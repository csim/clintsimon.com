<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>App Engine on Clint Simon</title>
    <link>http://clintsimon.com/tags/app-engine/</link>
    <description>Recent content in App Engine on Clint Simon</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Copyright</copyright>
    <lastBuildDate>Fri, 28 Oct 2011 08:00:00 -0800</lastBuildDate>
    <atom:link href="http://clintsimon.com/tags/app-engine/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>The case of the 30 day memcache timeout on app engine</title>
      <link>http://clintsimon.com/blog/2011/2011-10-28-The-case-of-the-30-day-memcache-timeout-on-app-engine/</link>
      <pubDate>Fri, 28 Oct 2011 08:00:00 -0800</pubDate>
      
      <guid>http://clintsimon.com/blog/2011/2011-10-28-The-case-of-the-30-day-memcache-timeout-on-app-engine/</guid>
      <description>&lt;p&gt;I ran into an interesting problem with Google app engine. It seems that the memcache time limit is enforced differently on the development server versus the production servers.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://code.google.com/p/memcached/wiki/FAQ#What_are_the_limits_on_setting_expire_time?_(why_is_there_a_30_d&#34;&gt;The documentation&lt;/a&gt; says that the time limit for a memcache key is 30 days. The behavior that I have observed is that if you set a memcache key to timeout at 30 days, the development server (on windows) will happily persist the data as expected.&lt;/p&gt;

&lt;p&gt;On the production servers, it seems that the behavior is much different. I have notice with a timeout of 30 days, that memcache will not only ignore the persisted key but it will also cause erratic behavior for instances in your application.&lt;/p&gt;

&lt;p&gt;Under these conditions a new instance of my application was start for each request! Obviously this adversely effects performance.&lt;/p&gt;

&lt;p&gt;Once I changed the memcache timeout to a lesser value (under 30 days), the problem stopped.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Google&#39;s new App Engine pricing</title>
      <link>http://clintsimon.com/blog/2011/2011-09-29-Googles-new-App-Engine-pricing/</link>
      <pubDate>Thu, 29 Sep 2011 08:00:00 -0800</pubDate>
      
      <guid>http://clintsimon.com/blog/2011/2011-09-29-Googles-new-App-Engine-pricing/</guid>
      <description>

&lt;p&gt;Google App engine is in the process of changing it&amp;rsquo;s pricing model. At present this new pricing model goes into effect on December 1, 2011. There has been quite an uproar among App engine developers. In some cases the new billing model raises monthly costs by more than 300%. This has cause quite a reaction among the community and the backlash is very real&lt;/p&gt;

&lt;h3 id=&#34;what-is-changing:9829541407e1bc2b452f513247e9d720&#34;&gt;What is changing?&lt;/h3&gt;

&lt;p&gt;The primary change is that Google is moving from a model where you are charged by CPU time to a model where you are charged by &amp;ldquo;instance time&amp;rdquo;. This means that google charges are not necessarily based on pure CPU use but rather on the amount of instances of your application the Google scheduler decides to run. To magnify matters, most web applications are IO bound and the current version of Python supported by App Engine is single threaded.&lt;/p&gt;

&lt;p&gt;That means that your application is probably using more instances that you think. Because one instance can only handle a fixed amount of traffic based on IO and threading, the scheduler is forced to create instances more often for Python applications. All of these circumstances add up to a much higher cost for developers.&lt;/p&gt;

&lt;p&gt;Google has added sliders that allow you to tweak the scheduler behavior. You can now change the maximum number of idle instances and the minimum pending wait time. This allow us to dictate how long is a acceptable waiting time per request and how many instances show be available for traffic spikes.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m personally glad these are available, although others disagree. I have found them to be helpful for my small(ish) application because latency is not a concern, so I can set the min latency up to around 700ms. This means that requests can wait to be served from an &lt;em&gt;existing&lt;/em&gt; instance. Basically all output from my application is cached, so my request processing time is under 100ms. Setting the min pending latency to 700ms basically means that my application can remain free. I like free.&lt;/p&gt;

&lt;p&gt;It appears as though CPU billing was a bad idea in the first place and Google is now correcting for this by changing to instance based billing. In the end, Google needs to pay for the physical resources an application uses and as it turns out web applications use very little CPU as compared to IO with the datastore or other APIs.&lt;/p&gt;

&lt;p&gt;So, is the dream of a true &amp;ldquo;Platform as a Service&amp;rdquo; dead? Yes and No. The precise billing aspect of PaaS is dead at Google for the moment, but App Engine (and PaaS for that matter) is not defined by this shortcoming. Ultimately Google has recognized that having an instance running costs money even if the CPU usage for that instance is zero. Said another way, memory costs money. An instance will always consume memory if it is running. And not only will it consume memory but Google will need to reserve all the memory that it &lt;em&gt;may&lt;/em&gt; need. This is a reality of physics.&lt;/p&gt;

&lt;p&gt;I think we have become a little spoiled in that we have come to expect that computing will always become cheaper over time. I wonder how much it would cost to build your own ultra scalable, redundant, highly replicated system?&lt;/p&gt;

&lt;h3 id=&#34;optimization:9829541407e1bc2b452f513247e9d720&#34;&gt;Optimization&lt;/h3&gt;

&lt;p&gt;In the new world of App Engine where instances are charged, the emphasis is now on eliminating IO bound activities. That means eliminate datastore calls, URL fetch call, etc. If you have instances that are waiting around for IO activities to complete, then you are running to many instances.&lt;/p&gt;

&lt;p&gt;Here are a few ideas:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Don&amp;rsquo;t pull more data than you need for the data store. Use &amp;ldquo;Select &lt;em&gt;key&lt;/em&gt;&amp;rdquo; where possible. Limit your fetches to the smallest possible row sets.&lt;/li&gt;
&lt;li&gt;Cache results when ever possible. If you are displaying the same data, then cache it per page, per user or per application.&lt;/li&gt;
&lt;li&gt;Use a Task Queue. Can this operation run in the background? Task queues can eliminate instances by way of pushing work for a dedicated backend.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;the-good-news:9829541407e1bc2b452f513247e9d720&#34;&gt;The good news&amp;hellip;&lt;/h3&gt;

&lt;p&gt;App Engine was not decommissioned. I know this sounds like little consolation, but many Google projects have been scrapped over the past 6 months and App Engine is not one of them. This shows that Google is willing to make difficult decisions when it comes to App Engine and that they are committed to having a PaaS offering for the long term.&lt;/p&gt;

&lt;p&gt;The bottom line is that Google has a right to at least break even on App Engine. The service is incredible, the free tier still exists and the new &lt;a href=&#34;http://code.google.com/appengine/sla.html&#34;&gt;SLA terms&lt;/a&gt; are top notch. App Engine is still a worth competitor in the PaaS market, even with the new pricing.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>